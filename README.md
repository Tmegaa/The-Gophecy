# Projet IA04 - A24 : La Goph√©tie

## üè´ Description

Dans cette simulation multi-agents, nous explorons l'√©volution de leur croyance: seront-ils fid√®les au langage Go?

Les agents, des √©tudiants d'ing√©nierie informatique au sein d'un campus, sont plus ou moins adh√©rents √† la doctrine du langage Go. Les plus croyants veulent persuader leurs camarades de la sup√©riorit√© de ce magnifique langage de programmation, alors que les plus sceptiques ont pour mission de dissuader les autres. Dans cette simulation nous allons nous poser une question: **Quelles politiques d'embrigadement fonctionnent le mieux ?**

## üîó Recup√©rer le projet du repository (git)

Pour simplement r√©cup√©rer le module et pouvoir faire tourner la simulation:

```{bash}
go install github.com/Tmegaa/The-Gophecy@latest
```
Les fichiers se trouvent dans le GOPATH dans le dossier `pkg/mod/gitlab.utc.fr/`
```{bash}
go run .
```

Dans le cas o√π vous voudriez r√©cup√©rer tout le projet (notamment les sources dans le dossier "/pdf"):

```{bash}
git clone https://github.com/Tmegaa/The-Gophecy.git
```

## üî¨  Tests avec diff√©rents cas de figure

> TODO: fill this

## üíª La Goph√©tie

### 1. üìê L'architecture

- backend: **go**
- frontend: **ebiten**

Packages:

- **agent**: gestion des agents, de l'environnement et des objets
- **carte**: gestion de la carte
- **simulation**: gestion de la simulation (l'affichage graphique, les interactions avec l'utilisateur‚Ä¶)
- **tile**: gestion des jeux de tuiles (soit les √©l√©ments sur la carte)
- **utils**: constantes et fonctions qui sont utiles dans les autres packages
- **gophecy**: contient le "main"

Une mod√©lisation des √©l√©ments de cette simulation:

![UML](/pdf/UML_Classe.png "UML des classes")

### 2.üö∂ Les agents

Les agents sont des √©tudiants en ing√©nierie informatique et ont donc des fortes opinions vis-√†-vis des langages de programmation. Dans cette simulation, on peut consid√©rer que ces croyances sont un peu sectaires... De plus, cette simulation a lieu dans un campus d'universit√©, les agents peuvent donc se d√©placer librement, mais ils auront des preferences par rapport √† leur fa√ßon de bouger.

Dans la boucle de perception, d√©lib√©ration et action de chaque agent, il y a un temps d'attente de 20ms entre chaque boucle.

Tous les agents ont la m√™me fonction de perception o√π ils re√ßoivent de l'environnement une liste des agents et des objets qui sont √† une certaine distance. Cet aire de perception, qui sera affich√©e comme un rectangle, va d√©pendre de l'acuit√© de l'agent. Il pourra donc d√©lib√©rer.

Nous verrons par la suite que les sous-types interviennent dans la prise de d√©cision. Les agents vont donc choisir parmi les actions suivantes:

- **Bouger** : L'agent va se d√©placer, avec ou sans but. Ses d√©placements ont une dur√©e limit√©e. Tout agent va choisir cette option s'il ne per√ßoit aucun autre agent ou objet √† proximit√©, mais aussi √† la fin des autres actions. C'est "l'action par d√©faut".
- **Utiliser un ordinateur** : L'agent va pouvoir acc√©der √† un ordinateur.
- **Prier** : Certains agents peuvent prier aupr√®s d'une statue.
- **Discuter** : Deux agents peuvent s'engager dans une conversation avec une dur√©e limit√©e. Chaque agent a un param√®tre "MaxLastTalked" qui indique avec combien de personnes il se rappelle d'avoir discut√©, la liste de ses derniers "MaxLastTalked" interlocuteurs est sauvegard√©e et constamment mise √† jour pour √©viter qu'un agent parle trop souvent aux m√™mes personnes.
- **Attendre** : Il ne va r√©aliser aucune action pendant une boucle. Il est envisageable par la suite d'impl√©menter un "temps d'attente", mais pour l'instant cette action n'a d'effet que pendant une seule boucle de perception, d√©lib√©ration et action.

#### 2.1 Les types d'agents

Le degr√© de croyance dans le langage Go est mod√©lis√© chez chaque agent par une variable "Opinion" qui prend comme valeur un float entre 0 et 1, 0 repr√©sentant un scepticisme total et 1 une croyance aveugle. En fonction de leur degr√© de croyance, les agents prendront un de ces 3 types:

Opinion|Type|Description|
:--------------: | :--------------: |------------- |
[0, 0.33[| Sceptique| Ne croit pas dans le langage Go et va essayer des dissuader ses camarades de l'utiliser.|
[0.33, 0.66]| Neutre| Est mitig√© et va √™tre influenc√© par tous les autres agents.|
]0.66, 1]| Croyant| Croit que le langage Go est incroyable et aura pour mission de r√©pandre sa croyance en plus d'essayer de l'augmenter.|

Apr√®s une modification de l'opinion d'un agent, on v√©rifie son type et on le met √† jour si besoin: les types ne sont donc pas statiques tout au long de la simulation, ils peuvent √©voluer.

Le type de chaque agent va influencer son comportement, particuli√®rement dans 4 domaines:

 1. **Leurs interactions avec d'autres agents** : Les conversations entre agents d'un m√™me type ou entre types diff√©rents vont avoir des effets diff√©rents. Ceci sera d√©taill√© plus tard dans ce rapport.
 2. **Leurs patrons de mouvement** : Chaque type va √©voluer dans l'espace de fa√ßon diff√©rente. Nous verrons ceci plus en d√©tail apr√®s.
 3. **Leurs choix de comportement** : les agents croyants et sceptiques pourront avoir un sous-type qui va influencer leurs choix.
 4. **Leurs actions sp√©cifiques** : Nous pouvons voir que les actions ne sont pas r√©alis√©s de la m√™me fa√ßon par tous les agents:

Action\Type Agent| Sceptique| Neutre| Croyant|
------------- | :--------------: | :--------------: |:--------------: |
Bouger| Type mouvement 1 | Type mouvement 2 |Type mouvement 3 |
Utiliser un ordinateur | D√©sinstalle Go | Regarde quel langage de programmation est install√© | Installe Go|
Prier | (action non r√©alisable) | Prie aupr√®s d'une statue | Peut prier aupr√®s d'une statue|

#### 2.2 Les sous-types d'agents

Aucun sous-type n'est possible pour les agents neutres. Cependant les croyants et les sceptiques ont la possibilit√© d'√™tre des pirates ou des convertisseurs. Ces sous-types rentrent en jeu dans le cas o√π un agent pourrait percevoir √† la fois un ou plusieurs agents proches en plus d'un ou plusieurs objets √† proximit√©.

Si le choix est pr√©sent√©, un pirate va choisir d'interagir avec un ordinateur plut√¥t qu'engager une conversation avec un autre agent. Pour les convertisseurs c'est l'inverse.

Les croyants vont avoir une plus grande tendance √† √™tre des convertisseurs alors que les sceptiques auront plus tendance √† √™tre des pirates.

La probabilit√© d'avoir un sous-type est de 70%.

#### 2.3. üìà L'√©volution des croyances

Il y a trois actions qui font √©voluer les croyances des agents: prier, discuter et utiliser un ordinateur.

Lors de l'utilisation d'un ordinateur, les sceptiques diminuent leur opinion de Go (et le d√©sinstallent si install√©), contrairement aux croyants qui l'augmentent (en installant Go). Les agents neutres vont voir leur opinion diminuer ou augmenter en fonction de si Go est install√© ou pas.

La pri√®re n'est disponible que pour les agents croyants et neutres: elle fait augmenter la croyance en Go, d'autant plus pour les agents neutres (qui d√©cident d'agir en fonction de leur foi). Les agents neutres vont cependant avoir moins de probabilit√©s de choisir la pri√®re.

Enfin, la fa√ßon la plus int√©ressante de faire √©voluer les croyances des agents est la discussion: dans le cas o√π un agent croyant et un sceptique d√©cident de parler, ils ne font qu'amplifier leur opinion de base. En effet, le croyant voit son opinion augmenter et le sceptique voit la sienne diminuer. C'est une mod√©lisation de deux personnes t√™tues qui ne vont pas pouvoir √©couter des arguments qu'ils jugent presque "extr√©mistes" de l'autre.

D'un autre c√¥t√©, les discussions entre un agent neutre et tout autre type d'agent vont voir intervenir bien plus de param√®tres: nous voyons entrer en jeu les relations entre les agents, un certain degr√© de charisme qui donne un certain poids aux conversations...

> Nous avons bas√© la mod√©lisation sur plusieurs articles, que l'on peut trouver dans le dossier "/pdf" de ce projet. De plus, le document [R√©sum√© et Analyse : Mod√®le d‚ÄôEndoctrinement par √©quations Diff√©rentielles](./pdf/Indoctrination_equation%20(1).pdf) d√©taille toutes les √©quations.

Tout d'abord, on mod√©lise les relations entre les agents. Un agent peut avoir une des relations suivantes avec un autre agent:

- Ennemi
- Amis
- Famille
- Pas de lien direct / Inconnu
  
Cette relation va avoir un effet sur le calcul des poids absolus. Pour chaque agent, nous allons attribuer le poids qu'il donne √† l'opinion d'un autre agent. Il va √™tre beaucoup plus confiant d'un ami que d'un inconnu par exemple. Ces poids absolus sont normalis√©s. Un agent va avoir une certaine confiance envers lui-m√™me, un poids absolu qu'il donne √† ses propres opinions, qui se traduit par la valeur r√©f√©renc√©e par son propre ID dans son dictionnaire de poids absolus.

Pour les poids relatifs, ce param√®tre de confiance en soi rentre en jeu. En effet, un agent A va avoir une certaine confiance g√©n√©rale sur sa propre opinion (poids absolu), une certaine confiance de sa propre opinion en parlant avec un agent B (poids relatif 1) et une certaine confiance dans l'opinion de l'agent B tout en prenant en compte non seulement leur relation mais aussi sa propre confiance (poids relatif 2).

$$
\displaystyle Rel_{A\to A /B}=\frac{Abs_{A\to A}}{Abs_{A\to A}+Abs_{A\to B}} \quad Rel_{A\to B/B}=\frac{Abs_{A\to B}}{Abs_{A\to A}+Abs_{A\to B}}
$$

Chaque agent a en plus un param√®tre personnel qui symbolise sa r√©ceptivit√©.

Lors d'une conversation, nous avons mod√©lis√© la mise √† jour des opinions des agents A et B de la fa√ßon suivante (cf. [source](./pdf/Indoctrination_equation%20(1).pdf) pour plus de d√©tails):

$$
\displaystyle NewO_{A} = Rel_{A\to A /B} * K_{A} * OldO_{A} * (1-OldO_{A}) + Rel_{A\to B /B} * OldO_{B}
$$
$$
\displaystyle NewO_{B} = Rel_{B\to A /A} * OldO_{A} + Rel_{B\to B /A} * OldO_{B} * K_{B} * OldO_{B} * (1-OldO_{B})
$$

- K est le param√®tre personnel
- NewO est la nouvelle opinion
- OldO est l'opinion courante
- Rel est le poids relatif que donne le premier agent √† l'opinion du deuxi√®me en connaissant l'interlocuteur.

Nous avions pr√©vu de rajouter un param√®tre de Charisme qui serait l'influence per√ßue d'un agent A sur un agent B, mais ceci n'as pas √©t√© impl√©ment√©.

#### 2.4 üèÉ Les strat√©gies de mouvement

Chaque type d'agent va avoir une strat√©gie de mouvement diff√©rente. cette strat√©gie pourra √™tre assign√©e lors du d√©but de la simulation par l'utilisateur, et c'est envisageable de la pr√©d√©finir avec des fichiers de configuration.

Les 4 strat√©gies de mouvement sont:

- **Random** : cette strat√©gie est la plus simple car une direction est choisie al√©atoirement.
- **Patrol** : l'agent va choisir un point vers lequel se diriger dans la carte. Il va choisir plusieurs point al√©atoirement au d√©but, puis il choisira le meilleur en lui assignant un score qui va d√©pendre de la distance √† parcourir pour arriver √† ce point, les potentiels obstacles √† √©viter et un facteur al√©atoire. Ce point peut rester constant tout le long de la simulation s'il n'est pas atteint, mais l'agent a aussi la possibilit√© de changer de point s'il atteint la position ou de prendre une direction al√©atoire.
- **HeatMap** : les agents maintiennent un historique des positions qu'ils ont d√©j√† visit√©. Avec cette strat√©gie, les agents vont essayer de se diriger vers les zones qu'ils ont personnellement visit√© le moins afin de parcourir des nouvelles positions le plus possible.
- **Center of Mass** : les agents vont chercher √† se d√©placer vers le centre de congr√©gations. Soit, en calculant le centre de masse des agents aux alentours, ces agents vont avoir comme objectif dans leur d√©placement un point qui les rapprochera le plus possible au plus grand nombre d'agents possible. Il y a tout de m√™me une petite chance de passer √† un mouvement al√©atoire pour √©viter un regroupement excessif.

Pour l'instant la vitesse des agents indiqu√©e lors de la cr√©ation n'a pas d'effet dans leur d√©placement, pour notre simulation il n'est pas vital que les agents bougent √† des vitesses diff√©rentes. Une modification √† envisager par la suite serait l'impl√©mentation des vitesses.

### 3. ‚ñ∂Ô∏è La simulation

Le backend est (√©videmment) r√©alis√© en Go, mais pour l'affichage nous avons utilis√© Ebiten.

Lorsqu'on lance la simulation, on donne le nombre d'agents, la dur√©e de la simulation et les strat√©gies de mouvement par type. La simulation est donc initialis√©e et l'affichage graphique est ouvert dans une autre fen√™tre.

Tout d'abord nous pouvons observer l'affichage (cette simulation comptait 40 agents):

![simu1](/images/simu_all.png "Capture d'√©cran de la simulation")

A gauche nous pouvons voir les informations pertinentes de la simulation, tel de que temps √©coul√©, la r√©partition des agents par type et le langage de programmation install√© sur les ordinateurs. A droite nous observons la carte avec les agents, les objets...

![simu2](/images/three_agents.png "Capture d'√©cran de trois agents")

Chaque type d'agent est affich√© avec une image diff√©rente: les croyants sont en noir, les sceptiques sont en rouge et les agents neutres sont en blanc. Le carr√© qui les entoure est leur zone de perception.

![simu3](/images/simu_click_agent.png "Capture d'√©cran affichage infos agent")

Lorsqu'on clique sur un agent (ici nous pouvons le voir tout √† droite, un sceptique rouge entour√© d'un carr√© jaune), nous pouvons lire sur le bandeau de gauche des informations pertinentes sur cet agent telles que son action courante, son historique de discussions, son param√®tre personnel de r√©ceptivit√©...

Pour l'instant, il n'est pas encore possible de faire un scroll dans ce bandeau, il n'est donc pas possible de voir toutes les relations que cet agent a avec le reste.

Lorsque l'agent s√©lectionn√© est en discussion avec un autre, nous avons les cette information aussi.

![simu4](/images/discussion_infos.png "Capture d'√©cran affichage informations sur discussion")

Un click sur un ordinateur nous donne des informations aussi:

![simu5](/images/click_computer.png "Capture d'√©cran affichage infos ordinateur")

Chaque action, autre que le mouvement, affiche une petite bo√Æte en dessus de l'agent avec le nom de l'action et une barre qui indique le temps restant pour compl√©ter cette action. Si cette action est une discussion, on affiche aussi le type de chaque agent.

![simu6](/images/discussion.png "Capture d'√©cran affichage action")

Lorsque la simulation finit, nous avons un petit compte-rendu avec la r√©partition des agents par type finale et l'opinion moyenne de tous les agents par rapport √† Go.

Par exemple, ici on a les r√©sultats d'une simulation de 50 agents dont les strat√©gies de mouvement √©taient toutes al√©atoires:

![simu7](/images/simu_end.png "Capture d'√©cran affichage √† la fin d'une simulation")

De plus, un graphique d√©taillant l'opinion globale sur Go en fonction du temps √©coul√© est sauvegard√©. Pour la m√™me simulation nous obtenons:

![simu8](/images/results_example.png "Graphique repr√©sentant la croyance moyenne de la population en fonction du temps")

### 4.üí° Id√©es pour la suite

Tout au long de ce rapport nous avons vu des am√©liorations possibles pour ce projet. Nous pouvons en explorer d'avantage.

En effet, nos agents ont un bool√©en qui indique s'ils sont vivants ou pas. Avec cette version de la simulation, il n'est pas possible de mourir, cependant il serait envisageable de rajouter des fonctionnalit√©s en rapport √† la sant√© des agents: un agent fatigu√© ou affam√© pourrait √™tre beaucoup plus influen√ßable qu'un agent en pleine sant√©! Des param√®tres de faim ou d'√©nergie avec des actions de type "Manger" ou "Dormir" (des fonctions ont √©t√© laiss√©es en commentaire pour montrer l'emplacement des fonctions dans notre architecture) seraient donc rajout√©es √† nos agents. La conclusion si un agent est beaucoup trop affam√© ou beaucoup trop fatigu√©? Notre bool√©en prendrait la valeur `false`.

De plus, nous explorons ici l'opinion vis √† vis de Go, mais l'√©volution que nous avions pr√©vu de base pour cette simulation serait l'introduction d'autres sectes! Que ce soit le C++ulte, le Hask Hell
la BASH astr√©e ou l'HTMLM, il serait tr√®s int√©ressant d'observer la concurrence des diff√©rentes croyances au sein d'une m√™me population.

Nous avions pens√© √† une liste (ou un map, peu importe), au lieu d'une seule valeur mod√©lisant l'opinion d'une personne. Il y aurait √† priori plus de types de croyants et des questions √† se poser:

- Est-ce qu'on peut √™tre croyant pour une seule secte ou pour plusieurs?
- Dans le cas o√π un agent devient croyant, que deviennent ses autres opinions?
- Quel est la nouvelle signification du scepticisme?

De plus, √©tant donn√© que cette simulation a lieu au sein d'un campus universitaire, nous pourrions rajouter des personnages tels que des professeurs qui instruisent un groupe d'agents.

Finalement, pour l'instant l'utilisateur ne peut pas intervenir dans la simulation. Il donne les param√®tres de d√©part, mais il ne peut pas agir apr√®s en dehors de la visualisation d'informations. Nous pourrions envisager d'ajouter des boutons qui permettraient √† l'utilisateur de rajouter des agents ou des objets en cours de route.

## üòá  Les Goph√®tes

- üå± Lepretre Thomas
- üê§ Perdereau Tom
- üåü Saby Loyola Sophie
- üëΩ Sporck Trombini Gabriel
